name: CPU Baseline

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  baseline:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Run unit tests
        run: |
          python3 -m unittest discover -s tests -p "test_*.py" -v

      - name: Run CPU-only baseline experiment
        run: |
          python3 experiments/fedavg_cpu_only.py --json-out baseline_metrics.json

      - name: Validate baseline thresholds
        run: |
          python3 scripts/check_baseline.py baseline_metrics.json \
            --max-accuracy-drop 0.03 \
            --min-int8-accuracy 0.82 \
            --min-comm-reduction 50 \
            --expected-schema-version 2

      - name: Run local classification baseline
        run: |
          python3 experiments/local_classification_baseline.py \
            --quiet \
            --json-out classification_metrics.json

      - name: Validate classification metrics
        run: |
          python3 scripts/check_classification.py classification_metrics.json \
            --expected-schema-version 1 \
            --min-accuracy 0.85 \
            --min-macro-f1 0.85 \
            --max-train-runtime-sec 2.0 \
            --max-latency-mean-ms 1.0

      - name: Run capacity fairness scenario
        run: |
          python3 experiments/fedavg_cpu_only.py \
            --simulate-client-capacity \
            --quiet \
            --json-out fairness_metrics.json

      - name: Validate fairness metrics
        run: |
          python3 scripts/check_fairness.py fairness_metrics.json \
            --expected-schema-version 2 \
            --min-int8-jain-improvement 0.05 \
            --min-int8-contributed-clients-gain 0.5

      - name: Run utility fairness stress scenario
        run: |
          python3 experiments/fedavg_classification_utility.py \
            --simulate-client-capacity \
            --dropout-rate 0.1 \
            --round-deadline-sweep 4.0,4.2 \
            --quiet \
            --json-out utility_fairness_metrics.json

      - name: Validate utility fairness metrics
        run: |
          python3 scripts/check_utility_fairness.py utility_fairness_metrics.json \
            --expected-schema-version 1 \
            --min-int8-jain-improvement 0.05 \
            --min-int8-gap-improvement 0.05 \
            --min-int8-contributed-clients-gain 0.5

      - name: Run federated adapter proxy experiment
        run: |
          python3 experiments/fedavg_adapter_intent.py \
            --seeds 7 \
            --samples-per-intent 12 \
            --rounds 20 \
            --local-steps 10 \
            --batch-size 8 \
            --learning-rate 0.26 \
            --int8-clip-percentile 0.98 \
            --quiet \
            --json-out adapter_intent_metrics.json

      - name: Validate adapter proxy metrics
        run: |
          python3 scripts/check_adapter_intent.py adapter_intent_metrics.json \
            --expected-schema-version 1

      - name: Run generality evaluation
        run: |
          python3 scripts/evaluate_generality.py --quiet --json-out generality_metrics.json

      - name: Validate generality metrics
        run: |
          python3 scripts/check_generality.py generality_metrics.json \
            --expected-schema-version 1

      - name: Run reproducibility sweep
        run: |
          python3 scripts/reproducibility_sweep.py \
            --seeds 7,17,27 \
            --quiet \
            --json-out reproducibility_metrics.json

      - name: Validate reproducibility metrics
        run: |
          python3 scripts/check_reproducibility.py reproducibility_metrics.json \
            --expected-schema-version 1

      - name: Run reduced benchmark suite
        run: |
          python3 scripts/benchmark_suite.py --mode reduced --quiet --json-out benchmark_metrics.json

      - name: Validate benchmark report
        run: |
          python3 scripts/check_benchmarks.py benchmark_metrics.json \
            --expected-schema-version 1 \
            --expected-mode reduced

      - name: Build pilot metrics report
        run: |
          python3 scripts/build_pilot_metrics.py \
            --last-cycle-ok \
            --step-count 1 \
            --uptime-ratio-24h 1.0 \
            --json-out pilot/pilot_metrics.json

      - name: Validate pilot metrics report
        run: |
          python3 scripts/check_pilot_metrics.py pilot/pilot_metrics.json \
            --expected-schema-version 1

      - name: Build pilot cohort metrics report
        run: |
          python3 scripts/build_pilot_cohort_metrics.py \
            --metrics pilot/pilot_metrics.json \
            --json-out pilot/pilot_cohort_metrics.json

      - name: Validate pilot cohort metrics report
        run: |
          python3 scripts/check_pilot_cohort.py pilot/pilot_cohort_metrics.json \
            --expected-schema-version 1 \
            --min-node-count 1

      - name: Generate pilot status report
        run: |
          python3 scripts/generate_pilot_status_report.py \
            --pilot-metrics pilot/pilot_metrics.json \
            --cohort-metrics pilot/pilot_cohort_metrics.json \
            --out reports/pilot_status.md

      - name: Validate cohort manifest
        run: |
          python3 scripts/check_cohort_manifest.py \
            pilot/cohort_manifest.json \
            --expected-schema-version 1 \
            --min-nodes 5 \
            --min-passed 0 \
            --summary-json-out pilot/cohort_onboarding_summary.json

      - name: Generate draft 14-day pilot report
        run: |
          python3 scripts/generate_pilot_14_day_report.py \
            --manifest pilot/cohort_manifest.json \
            --onboarding-summary pilot/cohort_onboarding_summary.json \
            --daily-cohort-glob 'pilot/runs/day*/pilot_cohort_metrics.json' \
            --incident-log pilot/incident_log.json \
            --out reports/pilot_14_day_report.md

      - name: Upload baseline metrics artifact
        uses: actions/upload-artifact@v4
        with:
          name: baseline-metrics
          path: baseline_metrics.json

      - name: Upload benchmark metrics artifact
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-metrics
          path: benchmark_metrics.json

      - name: Upload fairness metrics artifact
        uses: actions/upload-artifact@v4
        with:
          name: fairness-metrics
          path: fairness_metrics.json

      - name: Upload classification metrics artifact
        uses: actions/upload-artifact@v4
        with:
          name: classification-metrics
          path: classification_metrics.json

      - name: Upload utility fairness metrics artifact
        uses: actions/upload-artifact@v4
        with:
          name: utility-fairness-metrics
          path: utility_fairness_metrics.json

      - name: Upload adapter proxy metrics artifact
        uses: actions/upload-artifact@v4
        with:
          name: adapter-intent-metrics
          path: adapter_intent_metrics.json

      - name: Upload generality metrics artifact
        uses: actions/upload-artifact@v4
        with:
          name: generality-metrics
          path: generality_metrics.json

      - name: Upload reproducibility metrics artifact
        uses: actions/upload-artifact@v4
        with:
          name: reproducibility-metrics
          path: reproducibility_metrics.json

      - name: Upload pilot metrics artifact
        uses: actions/upload-artifact@v4
        with:
          name: pilot-metrics
          path: pilot/pilot_metrics.json

      - name: Upload pilot cohort metrics artifact
        uses: actions/upload-artifact@v4
        with:
          name: pilot-cohort-metrics
          path: pilot/pilot_cohort_metrics.json

      - name: Upload pilot status report artifact
        uses: actions/upload-artifact@v4
        with:
          name: pilot-status-report
          path: reports/pilot_status.md

      - name: Upload pilot 14-day draft report artifact
        uses: actions/upload-artifact@v4
        with:
          name: pilot-14-day-draft-report
          path: reports/pilot_14_day_report.md
